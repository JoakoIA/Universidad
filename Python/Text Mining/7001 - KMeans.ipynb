{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54497c3-100a-42ae-b31b-4c1e6622dd11",
   "metadata": {},
   "source": [
    "## __Text mining y Procesamiento de Lenguaje Natural (NLP)__\n",
    "\n",
    "__Profesor__: Anthony D. Cho\n",
    "\n",
    "__Tema__: Clustering de documentos\n",
    "\n",
    "__Método__: K-Means\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2a9f9-3531-473c-87e7-a187b2062341",
   "metadata": {},
   "source": [
    "__Dependencias__\n",
    "\n",
    "```{python}\n",
    "    python -m pip install nltk spacy\n",
    "    python -m spacy download en_core_web_sm\n",
    "    python -m spacy download es_core_news_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247e86e-b15c-45a0-a7c4-be1be7e77271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d30880a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dff896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "\n",
    "from string import punctuation\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy import load\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "## Instancia del modelo de lenguaje\n",
    "nlp = load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d89bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca90efb",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encontrar la ruta de cada archivo de interes\n",
    "path_docs = glob('*/doc*.txt')\n",
    "\n",
    "## Almacenamiendo de contenido de los documentos e id (nombre del archivo)\n",
    "corpus, doc_id = [], [] \n",
    "\n",
    "## Incio de proceso de carga de documentos\n",
    "if len(path_docs):\n",
    "    for file in path_docs:\n",
    "\n",
    "        ## Se carga el texto\n",
    "        text = open(file, 'r', encoding='utf-8').read()\n",
    "        \n",
    "        ## Se almacena el texto\n",
    "        corpus.append(text)\n",
    "        \n",
    "        id = file.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "        ## Se almacena el id\n",
    "        doc_id.append(id)\n",
    "else:\n",
    "    print('No corpus have found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a229a6",
   "metadata": {},
   "source": [
    "#### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limpieza de textos\n",
    "cleanTexts = []\n",
    "\n",
    "for doc in corpus:\n",
    "\n",
    "    # ## Remover numeros y puntuaciones\n",
    "    doc = re.sub(r'[\\\"\\¿\\°\\d+]', '', doc)\n",
    "    doc = [s for s in doc if s not in punctuation]\n",
    "    doc = ''.join(doc)\n",
    "\n",
    "    ## Normalización y remover stopwords\n",
    "    documento = nlp(doc.lower())\n",
    "    tokens = [word.text for word in documento]\n",
    "    doc = [word for word in tokens if word not in STOP_WORDS]\n",
    "    doc = ' '.join(doc)\n",
    "    doc = re.sub(pattern='\\s+', repl=' ', string=doc)\n",
    "    \n",
    "    ## Aplicar lemmatización\n",
    "    documento = nlp(doc)\n",
    "    lemmas = [word.lemma_ for word in documento]\n",
    "    doc = ' '.join(lemmas)\n",
    "    doc = re.sub(pattern='\\s+', repl=' ', string=doc)\n",
    "\n",
    "    ## Almacenado de contenido procesado\n",
    "    cleanTexts.append(doc)\n",
    "\n",
    "## Mostar contenido procesado\n",
    "cleanTexts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instancia del modelo\n",
    "model = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "## Ajuste del modelo y retorno de TF matrix como (docs, term)\n",
    "tf_sparse = model.fit_transform(cleanTexts)\n",
    "\n",
    "## Extraer la lista de los palabras que representan las columnas de la matriz generada\n",
    "vocabulary = model.get_feature_names_out()\n",
    "\n",
    "print('(shape) TFxIDF (terms, docs): {}'.format(tf_sparse.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb7b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0f898d7",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4cd7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clustering \n",
    "n_clusters = 3\n",
    "\n",
    "## Instancia del modelo\n",
    "model = KMeans(n_clusters=n_clusters,\n",
    "               n_init=10,  \n",
    "               random_state=0)\n",
    "\n",
    "## Ajuste del modelo\n",
    "model.fit(tf_sparse)\n",
    "\n",
    "## Extracción de las etiquetas asignadas\n",
    "etiquetas = model.labels_\n",
    "etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77401b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8603735a",
   "metadata": {},
   "source": [
    "#### Visualización en 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dfcef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se calcula la distancia basada en la distancia del coseno\n",
    "distance = cosine_distances(tf_sparse)\n",
    "\n",
    "## Instancia del modelo Multidimensional scaling (MDS)\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed',\n",
    "          normalized_stress='auto',\n",
    "          random_state=20231020, n_jobs=-1)\n",
    "\n",
    "## Aplicamos el método MDS a la data\n",
    "coordinates = mds.fit_transform(distance)\n",
    "X, Y = coordinates[:, 0], coordinates[:, 1]\n",
    "\n",
    "## Cluster-docs display\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in set(etiquetas):\n",
    "    \n",
    "    ## Docs filtering by label\n",
    "    mask = (etiquetas == i)\n",
    "    \n",
    "    ## Extract coordinates\n",
    "    temp_X, temp_Y = X[mask], Y[mask]\n",
    "    \n",
    "    ## plot coordinates\n",
    "    plt.plot(temp_X, temp_Y, 'o', label=f'Cluster {i}')\n",
    "\n",
    "## show legend\n",
    "plt.legend(loc=[1.01, 0.5])\n",
    "\n",
    "## add names to display space\n",
    "for i, doc_name in enumerate(doc_id):\n",
    "    plt.text(X[i], Y[i], doc_name, size=8)\n",
    "\n",
    "## complements\n",
    "plt.xlabel('latent feature 1'); plt.ylabel('latent feature 2');\n",
    "plt.title('Cluster visualization')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6739b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d145e1af",
   "metadata": {},
   "source": [
    "## Busqueda del mejor número de clusteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Almacenador de resultados\n",
    "scores = {'k': [], \n",
    "          'SSE': [],\n",
    "          'Silhouette': [],\n",
    "          'Davies_Bouldin': []}\n",
    "\n",
    "for n_clusters in tqdm(range(2, 7)):\n",
    "\n",
    "    ## Instancia del modelo\n",
    "    model = KMeans(n_clusters=n_clusters,\n",
    "                   n_init=10,  \n",
    "                   random_state=0)\n",
    "\n",
    "    ## Ajuste del modelo\n",
    "    model.fit(tf_sparse)\n",
    "\n",
    "    ## computo de la métrica de Silhountte\n",
    "    scores['Silhouette'].append(silhouette_score(tf_sparse.toarray(), model.labels_))\n",
    "\n",
    "    ## computo de la métrica de Davis Bouldin\n",
    "    scores['Davies_Bouldin'].append(davies_bouldin_score(tf_sparse.toarray(), model.labels_))\n",
    "\n",
    "    ## Almacenado del SSE y número de clusteres\n",
    "    scores['SSE'].append(model.inertia_)\n",
    "    scores['k'].append(n_clusters)\n",
    "\n",
    "\n",
    "## Convertir los resultados en un dataframe\n",
    "scores = DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc50646",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe07deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(1, 4):\n",
    "    plt.subplot(3, 1, i)\n",
    "    plt.plot(scores.iloc[:,0], scores.iloc[:,i], '-o', label=scores.columns[i])\n",
    "    plt.title(scores.columns[i])\n",
    "    plt.xlabel('Cantidad de clusteres')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b7f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
