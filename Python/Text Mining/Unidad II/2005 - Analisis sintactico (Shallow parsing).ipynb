{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f283511-48c4-407f-97b0-4068b88c5dcb",
   "metadata": {},
   "source": [
    "## __Text mining y Procesamiento de Lenguaje Natural (NLP)__\n",
    "\n",
    "__Profesor__: Anthony D. Cho\n",
    "\n",
    "__Tema__: Análisis sintáctico\n",
    "\n",
    "__Método__: Shallow parsing \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec4f2c-6056-4c5d-9187-e0f5754e5064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d714fc3-4665-4e00-a50b-c834b4997a18",
   "metadata": {},
   "source": [
    "__Dependencias__\n",
    "\n",
    "```python\n",
    "    python3 -m pip install nltk spacy\n",
    "    python3 -m spacy download en_core_web_sm\n",
    "    python3 -m spacy download es_core_news_sm\n",
    "    \n",
    "    python3 -m pip install svglib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2677d6a-8321-4273-b80b-a5d573759ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb99afea-02eb-47de-968f-ea5bd152a152",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d041d32-d04f-4b0f-9d46-62972acda625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import load\n",
    "\n",
    "## Cargar el modelo del lenguaje\n",
    "nlp = load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4321a-5824-4953-8022-99461ca3da5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c460e5a1-f878-458b-aa8d-dcd89abbe034",
   "metadata": {},
   "source": [
    "### Declaración de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ac787-eb9a-4bb0-9131-5b3aa317d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NP_chunk(text):\n",
    "    \"\"\"\n",
    "        DESCRIPTION:\n",
    "            Extract chunked noun-pronouns (NP) from text based language-model\n",
    "        \n",
    "        INPUT:\n",
    "            @param text: a corpus document\n",
    "            @type text: str\n",
    "        \n",
    "        OUTPUT\n",
    "            @param NP_list: Chunked NP list.\n",
    "            @type NP_list: list\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Apply language model to a text\n",
    "    document = nlp(text)\n",
    "    \n",
    "    ## Extract chunked NP\n",
    "    NP_list = [chunk.text for chunk in document.noun_chunks]\n",
    "    \n",
    "    ## Return chunked NP list\n",
    "    return NP_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397e316-ae40-448d-8eaf-0387366f5752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80057e8c-df9c-467c-b7a7-e0d280e6a40a",
   "metadata": {},
   "source": [
    "## Ejecuciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780f8ed-740f-453e-b91c-a9391aeea135",
   "metadata": {},
   "source": [
    "#### Carga de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Data/texto_01.txt\"\n",
    "\n",
    "## Abrir el archivo de texto plano\n",
    "file = open(file=filename, mode='r', encoding='utf-8')\n",
    "\n",
    "## Leer el contenido\n",
    "text = file.read()\n",
    "\n",
    "## Cerrar el archivo\n",
    "file.close()\n",
    "\n",
    "## Mostrar información\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5179022-e17b-4f58-967c-4810fe4ac719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06ebd176",
   "metadata": {},
   "source": [
    "#### Extracción de pronombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos el modelo de lenguaje al texto\n",
    "documento = nlp(text=text)\n",
    "\n",
    "## Extraer los pronombres del modelo de lenguaje\n",
    "NP_list = [chunk.text for chunk in documento.noun_chunks]\n",
    "\n",
    "## Mostrar lista extraidas\n",
    "print(NP_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1a785-d2bf-405b-ab1a-d1b60aa4bf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
