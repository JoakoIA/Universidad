{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54497c3-100a-42ae-b31b-4c1e6622dd11",
   "metadata": {},
   "source": [
    "## __Text mining y Procesamiento de Lenguaje Natural (NLP)__\n",
    "\n",
    "__Profesor__: Anthony D. Cho\n",
    "\n",
    "__Tema__: Analisis semantico\n",
    "\n",
    "__Método__: Latent Semantic Analysis (Word Embedding)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2a9f9-3531-473c-87e7-a187b2062341",
   "metadata": {},
   "source": [
    "__Dependencias__\n",
    "\n",
    "```{python}\n",
    "    python -m pip install nltk gensim\n",
    "    python -m spacy download en_core_web_sm\n",
    "    python -m spacy download es_core_news_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247e86e-b15c-45a0-a7c4-be1be7e77271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d30880a",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dff896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "from string import punctuation\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy import load\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "## Instancia del modelo de lenguaje\n",
    "nlp = load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d89bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca90efb",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encontrar la ruta de cada archivo de interes\n",
    "path_docs = glob('*/doc*.txt')\n",
    "\n",
    "## Almacenamiendo de contenido de los documentos e id (nombre del archivo)\n",
    "corpus, doc_id = [], [] \n",
    "\n",
    "## Incio de proceso de carga de documentos\n",
    "if len(path_docs):\n",
    "    for file in path_docs:\n",
    "\n",
    "        ## Se carga el texto\n",
    "        text = open(file, 'r', encoding='utf-8').read()\n",
    "        \n",
    "        ## Se almacena el texto\n",
    "        corpus.append(text)\n",
    "        \n",
    "        id = file.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "        ## Se almacena el id\n",
    "        doc_id.append(id)\n",
    "else:\n",
    "    print('No corpus have found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a229a6",
   "metadata": {},
   "source": [
    "#### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limpieza de textos\n",
    "cleanTexts = []\n",
    "\n",
    "for doc in corpus:\n",
    "\n",
    "    # ## Remover numeros y puntuaciones\n",
    "    doc = re.sub(r'[\\\"\\¿\\°\\d+]', '', doc)\n",
    "    doc = [s for s in doc if s not in punctuation]\n",
    "    doc = ''.join(doc)\n",
    "\n",
    "    ## Normalización y remover stopwords\n",
    "    documento = nlp(doc.lower())\n",
    "    tokens = [word.text for word in documento]\n",
    "    doc = [word for word in tokens if word not in STOP_WORDS]\n",
    "    doc = ' '.join(doc)\n",
    "    doc = re.sub(pattern='\\s+', repl=' ', string=doc)\n",
    "    \n",
    "    ## Aplicar lemmatización\n",
    "    documento = nlp(doc)\n",
    "    lemmas = [word.lemma_ for word in documento]\n",
    "    doc = ' '.join(lemmas)\n",
    "    doc = re.sub(pattern='\\s+', repl=' ', string=doc)\n",
    "\n",
    "    ## Almacenado de contenido procesado\n",
    "    cleanTexts.append(doc.split(' '))\n",
    "\n",
    "## Mostar contenido procesado\n",
    "for line in cleanTexts:\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b9843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4520278",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instancia del modelo\n",
    "model = Word2Vec(sentences=cleanTexts, ## <- lista de documentos en tokens\n",
    "                 vector_size=4, ## <- Embedding size\n",
    "                 window=2, \n",
    "                 min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extraer la lista de vocabulario\n",
    "vocabulary = model.wv.index_to_key\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Representaciones en el espacio latente\n",
    "print(model.wv['laptop'])\n",
    "print(model.wv['razer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computo de similitud mediante coseno. \n",
    "model.wv.similarity('laptop', 'silicio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consultar por los términos más similares\n",
    "model.wv.most_similar('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377017f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive='laptop', negative='carlos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925cfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorsVisualizer(vocabulary, vectors):\n",
    "    \"\"\"\n",
    "        DESCRIPTION:\n",
    "            2D-vector visualizer. The first 2 coordinates are taken for visualizing.\n",
    "        \n",
    "        INPUT:\n",
    "            @param vocabulary: list of terms\n",
    "            @type vocabulary: list\n",
    "            \n",
    "            @param vectors: latent space matrix representation\n",
    "            @type vectors: numpy.ndarray\n",
    "        \n",
    "        OUTPUT:\n",
    "            Scattered graphic\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Pairs (x,y) allocation\n",
    "    x, y = [], []\n",
    "    for v in vectors:\n",
    "        x.append( v[0] )\n",
    "        y.append( v[1] )\n",
    "    \n",
    "    ## Display-space instance\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.title('Vector representation')\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        plt.annotate(text=vocabulary[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom'\n",
    "                     )\n",
    "    plt.xlabel('latent feature 1'); plt.ylabel('latent feature 2');\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Terms visualizer\n",
    "mds_2D = MDS(normalized_stress='auto', random_state=10).fit_transform(model.wv.vectors)\n",
    "vectorsVisualizer(vocabulary, mds_2D[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Representación del vocabulario en el espacio latente\n",
    "vocabulary_latent = DataFrame(data=model.wv.vectors, index=vocabulary)\n",
    "vocabulary_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1aa32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similitudes = 1-cosine_similarity(model.wv.vectors)\n",
    "plt.matshow(similitudes[:20, :20])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
