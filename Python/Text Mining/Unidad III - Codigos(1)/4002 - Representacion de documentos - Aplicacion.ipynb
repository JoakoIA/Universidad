{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54497c3-100a-42ae-b31b-4c1e6622dd11",
   "metadata": {},
   "source": [
    "## __Text mining y Procesamiento de Lenguaje Natural (NLP)__\n",
    "\n",
    "__Profesor__: Anthony D. Cho\n",
    "\n",
    "__Tema__: Representación de documentos\n",
    "\n",
    "__Método__: Modelo de espacio vectorial\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2a9f9-3531-473c-87e7-a187b2062341",
   "metadata": {},
   "source": [
    "__Dependencias__\n",
    "\n",
    "```{python}\n",
    "    python -m pip install nltk spacy\n",
    "    python -m spacy download en_core_web_sm\n",
    "    python -m spacy download es_core_news_sm\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d925b5",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247e86e-b15c-45a0-a7c4-be1be7e77271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "from numpy import zeros\n",
    "\n",
    "from string import punctuation\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy import load\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "## Instancia del modelo de lenguaje\n",
    "nlp = load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74479b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90ad1ae",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encontrar la ruta de cada archivo de interes\n",
    "path_docs = glob('*/doc*.txt')\n",
    "\n",
    "## Almacenamiendo de contenido de los documentos e id (nombre del archivo)\n",
    "corpus, doc_id = [], [] \n",
    "\n",
    "## Incio de proceso de carga de documentos\n",
    "if len(path_docs):\n",
    "    for file in path_docs:\n",
    "\n",
    "        ## Se carga el texto\n",
    "        text = open(file, 'r', encoding='utf-8').read()\n",
    "        \n",
    "        ## Se almacena el texto\n",
    "        corpus.append(text)\n",
    "        \n",
    "        id = file.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "        ## Se almacena el id\n",
    "        doc_id.append(id)\n",
    "else:\n",
    "    print('No corpus have found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa429b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639498ed",
   "metadata": {},
   "source": [
    "#### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce335e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limpieza de textos\n",
    "cleanTexts = []\n",
    "\n",
    "for doc in corpus:\n",
    "\n",
    "    ## Remover numeros y puntuaciones\n",
    "    doc = re.sub(r'[\\\"\\¿\\°\\d+]', '', doc)\n",
    "    doc = [s for s in doc if s not in punctuation]\n",
    "    doc = ''.join(doc)\n",
    "\n",
    "    ## Normalización y remover stopwords\n",
    "    documento = nlp(doc.lower())\n",
    "    tokens = [word.text for word in documento]\n",
    "    doc = [word for word in tokens if word not in STOP_WORDS]\n",
    "    doc = ' '.join(doc)\n",
    "    doc = re.sub(pattern='\\s+', repl=' ', string=doc)\n",
    "    \n",
    "    ## Aplicar lemmatización\n",
    "    documento = nlp(doc)\n",
    "    lemmas = [word.lemma_ for word in documento]\n",
    "    doc = ' '.join(lemmas)\n",
    "    doc = re.sub(pattern='\\s+', repl=' ', string=doc)\n",
    "\n",
    "    ## Almacenado de contenido procesado\n",
    "    cleanTexts.append(doc)\n",
    "\n",
    "## Mostar contenido procesado\n",
    "cleanTexts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a985e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ca07a8",
   "metadata": {},
   "source": [
    "## Construcción de TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instancia del modelo\n",
    "model = TfidfVectorizer(use_idf=True,      # <--\n",
    "                        norm=None,          # <--\n",
    "                        ngram_range=(1,1),\n",
    "                        binary=False        \n",
    "                        )\n",
    "\n",
    "## Ajuste del modelo y retorno de TF matrix\n",
    "tf_sparse = model.fit_transform(cleanTexts)\n",
    "\n",
    "## Extraer Vocabulario creado por el modelo (dict :: key (word), value (index))\n",
    "vocabulary = model.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sorted(vocabulary.items(), key=lambda x: x[1])\n",
    "features = [f for f, _ in features]\n",
    "\n",
    "tf_table = DataFrame(tf_sparse.toarray(), columns=features, index=doc_id)\n",
    "tf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14207702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0280db",
   "metadata": {},
   "source": [
    "#### Cosntrucción de un app prototipo para encontrar los 3 documentos más parecidos a una consulta realizada por un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta = input('Inserte lo que desea buscar').lower()\n",
    "print(consulta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d976e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se codifica la consulta con el vocabulario generado por el modelo vectorial \n",
    "consulta_vsm = zeros(len(vocabulary))\n",
    "\n",
    "## Se aplica lemmaticación\n",
    "documento = nlp(consulta)\n",
    "lemmas = [word.lemma_ for word in documento]\n",
    "\n",
    "## Completar la inormación codificacda en el arreglo declarado \"consulta_vsm\"\n",
    "for word in lemmas:\n",
    "    try:\n",
    "        vocabulary[word]\n",
    "    except:\n",
    "        print('word: {} not recognized.'.format(word))\n",
    "    else:\n",
    "        i = vocabulary[word]\n",
    "        consulta_vsm[i] +=1\n",
    "\n",
    "## Mostrar codificación\n",
    "consulta_vsm = consulta_vsm*model.idf_\n",
    "consulta_vsm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326aab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se calcula similitud entre la consulta y los documentos\n",
    "similitudes = cosine_similarity(X=consulta_vsm.reshape(1, -1), \n",
    "                                Y=tf_table)\n",
    "\n",
    "similitudes = DataFrame(data={'similarity': similitudes.flatten(), 'docs': tf_table.index.to_list()})\n",
    "similitudes = similitudes.sort_values(by='similarity', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1337f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "similitudes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mostrar el contenidos de los tres documentos encontrados\n",
    "for i in range(3):\n",
    "\n",
    "    doc = similitudes.iloc[i, 1]\n",
    "    index = doc_id.index(doc)\n",
    "\n",
    "    print(corpus[index])\n",
    "    print('*'*60, end=3*'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
